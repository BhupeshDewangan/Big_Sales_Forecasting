# -*- coding: utf-8 -*-
"""Big Mart Sales Forcasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12h-GLWp_CYBz5FLgByyx0K7u1WnHUH--

# **The Problem Description**

The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and find out the sales of each product at a particular store.

Using this model, BigMart will try to understand the properties of products and stores which play a key role in increasing sales.

## Importing all the Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

"""## Load the Data"""

train = pd.read_csv('/content/TrainData.csv')

train.columns

train.info()

train.describe()

print(train.shape)

test = pd.read_csv('/content/TestData.csv')

test.shape

"""## Checking Null Values"""

train.isnull().sum()

"""## Lets Visualize The Data for better Understanding"""

sns.scatterplot(x = 'Item_Visibility', y = 'Item_Outlet_Sales', data = train)
plt.title("Visibility vs Outlet Sales")
plt.show()

sns.barplot(x = 'Outlet_Identifier', y = 'Item_Outlet_Sales', data = train,
            palette = 'magma', capsize = 0.5, saturation = 8, ci = 'sd')
plt.title("Outlet vs Outlet Sales")
plt.xticks(rotation=90)

plt.show()

"""## Check which item sold the most"""

sns.barplot(x = 'Item_Type', y = 'Item_Outlet_Sales', data = train,
            palette = 'hls')
plt.title("Item type vs Outlet Sales")
plt.xticks(rotation=90)

plt.show()

"""## Find the outlier using Box Plot"""

sns.boxplot(x = 'Item_Type', y = 'Item_MRP', data = train, palette = 'Paired')
plt.xticks(rotation=90)
plt.show()

"""Finding 1 : Health and Hygiene has outlier.

## Data cleaning
"""

train['Item_Fat_Content'].value_counts()

len(train['Item_Visibility'].value_counts())

"""Finding 2 : Item Visibility Cannot be 0"""

train['Outlet_Size'].value_counts()

"""## Quick Observation from Dataset So Far:
1. Item_Fat_Content has mismatched Levels like LF = Low Fat, reg = Regular
2. Min(Item_Visibility) = 0, which is practically not possible, Treating 0's as Missing Values
3. Item_weight has 1463 Missing Values.
4. Outlet_size has also missing values of 2410.
"""

train['Item_Outlet_Sales']

test['Item_Outlet_Sales'] = 1
test['Item_Outlet_Sales'].head()

test.shape

train_copy = train.copy()
test_copy = test.copy()

combined = pd.concat([train, test])
combined.sample()

combined.shape

"""## Filling Outlet Size

Outlet size depens on the outlet type and the location of outlet
"""

crosstable = pd.crosstab(train['Outlet_Size'], train['Outlet_Type'])
crosstable

dic = {'Grocery Store' : 'Small'}

s = train.Outlet_Type.map(dic)

train.Outlet_Size = train.Outlet_Size.combine_first(s)

train['Outlet_Size'].value_counts()

train.isnull().sum(axis = 0)

"""In real world it is mostly seen that outlet size varies with the location of the outlet, hence checking betwwen the same"""

crosstable = pd.crosstab(train['Outlet_Size'], train['Outlet_Location_Type'])
crosstable

"""From the above table it is evident that all the Tier 2 stores are of small types

Therefore mapping Tier 2 store and small size
"""

dic = {'Tier 2': 'Small'}

s = train['Outlet_Location_Type'].map(dic)

train['Outlet_Size'] = train['Outlet_Size'].combine_first(s)

train['Outlet_Size'].value_counts()

train.isnull().sum(axis=0)

train.Item_Identifier.value_counts().sum()

"""Outlet size missing values have been imputed

Instead of imputing with the overall mean of all the items. It would be better to impute it with the mean of particular item type - Food,Dricks,Non-Consumable. Did this as some products may be on the heavier side and some on the lighter.
"""

train['Item_Weight'] = train['Item_Weight'].fillna(train.groupby('Item_Identifier')['Item_Weight'].transform('mean'))

train.isnull().sum()

train[train.Item_Weight.isnull()]

"""The above 4 item weights werent imputed because in the dataset there is only one record for each of them. Hence mean could not be caculated

So, we will fill Item_Weight by the corresponding Item_Type for these 4 values
"""

# List of item types
item_type_list = train.Item_Type.unique().tolist()
item_type_list

# grouping based on item type and calculating mean of item weight
Item_Type_Means = train.groupby('Item_Type')['Item_Weight'].mean()

Item_Type_Means = Item_Type_Means.sort_values(ascending=False)

Item_Type_Means

# Mapping item weight to item type mean

for i in item_type_list:
    dic = {i:Item_Type_Means[i]}
    s = train.Item_Type.map(dic)

    train.Item_Weight = train.Item_Weight.combine_first(s)

Item_Type_Means = train.groupby('Item_Type')['Item_Weight'].mean()

train.isnull().sum()

Item_Type_Means = Item_Type_Means.sort_values(ascending=False)

"""Missing values for item_weight have been imputed"""

train.Item_Weight.isnull().any()  # no missing value

"""# Imputing for item visibility

Item visibility cannot be 0 and should be treated as missing values and imputed


"""

train.Item_Visibility.value_counts().head() # There are 526 values with 0 Item visibility

"""Imputing with mean of item_visibility of particular item identifier category as some items may be more visible (big - TV,Fridge etc) and some less visible (Shampoo Sachet,Surf Excel and other such small pouches)"""

#Replacing 0's with NaN

train.Item_Visibility.replace(to_replace = 0.000000, value = np.NaN, inplace =True)

train.Item_Visibility = train.Item_Visibility.fillna(train.groupby('Item_Identifier')['Item_Visibility'].transform('mean'))

train.Item_Visibility.value_counts().head()

train.isnull().sum()

"""
### Renaming Item_Fat_Content levels
"""

train.Item_Fat_Content.value_counts()

train.Item_Fat_Content.replace(to_replace=["LF","low fat"],value="Low Fat",inplace=True)
train.Item_Fat_Content.replace(to_replace="reg",value="Regular",inplace=True)

train.Item_Fat_Content.value_counts()

train['Outlet_Establishment_Year']

train['Outlet_Year'] = (2013 - train.Outlet_Establishment_Year)

print(train["Outlet_Year"])
print(train["Outlet_Establishment_Year"])

"""### Encoding Categorical Variables"""

var_cat = train.select_dtypes(include=[object])
var_cat.head()
var_cat.columns

var_cat = var_cat.columns.tolist()

var_cat = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']

var_cat

train['Item_Type_New'] = train.Item_Identifier
train.Item_Type_New.head(10)

train.Item_Type_New.replace(to_replace="^FD*.*",value="Food",regex=True,inplace=True)
train.Item_Type_New.replace(to_replace="^DR*.*",value="Drinks",regex=True,inplace=True)
train.Item_Type_New.replace(to_replace="^NC*.*",value="Non-Consumable",regex=True,inplace=True)

train.head()

le = LabelEncoder()

train['Outlet'] = le.fit_transform(train.Outlet_Identifier)
train['Item'] = le.fit_transform(train.Item_Type_New)
train.head()

for i in var_cat:
    train[i] = le.fit_transform(train[i])

train.head()

corrmat = train.select_dtypes(include='number').corr()

# corrmat = train.corr()
corrmat

f, ax = plt.subplots(figsize = (15,10))

sns.heatmap(corrmat, annot = True, ax = ax, cmap = 'YlGnBu', linewidths = 0.1, square = True)
plt.show()

"""# Predictive Modelling"""

predictors=['Item_Fat_Content','Item_Visibility','Item_Type','Item_MRP','Outlet_Size','Outlet_Location_Type','Outlet_Type','Outlet_Year',
            'Outlet','Item','Item_Weight']

seed = 240
np.random.seed(seed)

X = train[predictors]
y = train.Item_Outlet_Sales

X.head(4)

y.head()

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state = 42)

X_train.shape

print(y_test.shape)

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score,cross_val_predict
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
from sklearn import metrics
import statsmodels.api as sm
from sklearn.linear_model import Lasso, Ridge

lr = LinearRegression()

model = lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

y_pred[:5]

"""# Plot the Model"""

plt.scatter(y_test, y_pred)
plt.show()

# Accuracy Score

print("Linear Regression Model Score:", model.score(X_test, y_test))

ori_val = y_test

# Root Means Square Error
rmse = np.sqrt(metrics.mean_squared_error(ori_val, y_pred))

print("Linear Regression R2 score: ",metrics.r2_score(ori_val, y_pred))

print("Linear Regression RMSE: ", rmse)

"""# Linear Regression wihtout cross validation:

* Linear Regression R2 score:  0.50521
* Linear Regression RMSE:  1168.377


"""

# LR with Statsmodels

x = sm.add_constant(X_train)
res = sm.OLS(y_train, x).fit()

res.summary()

y_pred = res.predict(x).rename("y_pred")

y_pred

y_pred_df = pd.DataFrame({"y_pred": y_pred})

joined = x.join(y_pred)
joined.head()

"""# Performing Cross Validation

"""

# Perform 6-fold Cross Validate

score = cross_val_score(model, X, y, cv = 5)

print("LR Cross Val Score: ", score)

predict = cross_val_predict(model, X, y, cv = 6)
predict[:5]

plt.scatter(y,predict)
plt.show()

accuracy = metrics.r2_score(y,predict)
print("Linear Regression R2 with CV: ",accuracy)

rmse = np.sqrt(metrics.mean_squared_error(y,predict))
print("Linear Regression RMSE with CV:",rmse)

"""## Linear Regression with Cross- Validation

* Linear Regression R2 with CV: 0.501

* Linear Regression RMSE with CV: 1205.05

# Using KFold Validation
"""

def cal_mat(X_train, y_train, X_test, y_test, model):
    '''fits model and returns the RMSE for in-sample error and out-of-sample error'''
    model.fit(X_train, y_train)

    train_error = cal_train_error(X_train , y_train, model)

    val_error = cal_val_error(X_test, y_test, model)

    return train_error, val_error

def cal_train_error(X_train , y_train, model):
    '''returns in-sample error for already fit model.'''

    predictions = model.predict(X_train)
    mse = metrics.mean_squared_error(y_train, predictions)
    rmse = np.sqrt(mse)
    return mse

def cal_val_error(X_test, y_test, model):
    '''returns out-of-sample error for already fit model.'''

    predictions = model.predict(X_test)
    mse = metrics.mean_squared_error(y_test, predictions)
    rmse = np.sqrt(mse)
    return mse

kf = KFold(n_splits = 10)

kf.get_n_splits(X)

print(kf)

alphas = [1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1]

for alpha in alphas:

    train_errors = []
    val_errors = []

    for train_idx, val_idx in kf.split(X_train, y_train):
      X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
      y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

      lasso_model = Lasso(alpha = alpha, fit_intercept = True, random_state = 77)

      train_error, val_error = cal_mat(X_train, y_train, X_val, y_val, lasso_model)

      train_errors.append(train_error)
      val_errors.append(val_error)


    # generate Report

    print('alpha: {:6} | mean(train_error): {:7} | mean(val_error): {}'.
          format(alpha,
                 round(np.mean(train_errors),4),
                 round(np.mean(val_errors),4)))

"""# Decision Tree Regressor

"""

dt = DecisionTreeRegressor()

dt.fit(X_train, y_train)

y_pred2 = dt.predict(X_test)

y_pred2[:5]

results = pd.DataFrame({'Actual':y_test,'Predicted':y_pred2})
results.head()

print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred2))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred2))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred2)))

"""# Decision Tree Regression with Kfold validation

* Mean Absolute Error: 1049.1455
* Mean Squared Error: 2505760.9516
* Root Mean Squared Error: 1582.9595

# Random Forest Regressor
"""

rf = RandomForestRegressor()

rf.fit(X_train, y_train)

y_pred3 = rf.predict(X_test)
y_pred3[:5]

rmse = np.sqrt(metrics.mean_squared_error(y_test,y_pred3))
rmse

print(metrics.r2_score(y_test,y_pred3))

results2 = pd.DataFrame({'Actual':y_test,'Predicted': y_pred3})
results2.head()

"""# Randorm Forest Regression with kfold validation score

* RMSE: 1104.38
* R2 Score: 0.55
"""